# Mini API Rate Limiter & Log Analyzer

A high-performance API rate limiting system with multi-worker concurrency and comprehensive log analysis capabilities.

## Features

- âœ… **Sliding Window Rate Limiting** with Redis (sorted sets + hash tables)
- âœ… **Multi-Worker Clustering** for concurrent request handling
- âœ… **Log Analysis** with latency distribution (p50, p95, p99) and error pattern detection
- âœ… **Performance Optimized** for high-traffic scenarios
---
## Quick Start

### Prerequisites
- Node.js (v14+)
- Redis (cloud or local)

### Installation

```bash
git clone <your-repo-url>
cd Mini-Api-Rate-Limiter
npm install
```

### Configuration
Update Redis connection in `src/rate-limitter/services/redisclient.js`:
```javascript
url: 'redis://:<password>@<endpoint>:<port>'
```
---

## Usage
### 1. Start Rate Limiter Server

```bash
npm run start:limiter
```
Server runs on `http://localhost:3000`

**Endpoints**:
- `GET /api/test` - Rate-limited (10 req/min per IP)
- `GET /api/unlimited` - No rate limit

### 2. Run Log Analyzer

Place your logs in `data/sample_api_logs.json`, then:

```bash
npm run analyze
```
Output saved to `src/log-analyzer/output/summary.json`

---
## Testing

### Test Rate Limiting (Sequential)
```bash
npm run test:sequential
```
**Expected**: Clean progression 1/10 â†’ 2/10 â†’ ... â†’ 10/10 â†’ BLOCKED

### Test Concurrency (Multi-Worker)
```bash
npm run test:cluster
```
**Expected**: Different worker PIDs handling requests simultaneously

### Manual Test
```bash
# Send multiple requests
for i in {1..15}; do curl http://localhost:3000/api/test; sleep 0.2; done
```

---
## What to Expect

### Rate Limiter Logs
```
âœ… Allowed | IP: ::1 | Worker PID 1234: 1 req(s) | Total in Redis: 1/10
âœ… Allowed | IP: ::1 | Worker PID 1235: 1 req(s) | Total in Redis: 2/10
...
âœ… Allowed | IP: ::1 | Worker PID 1234: 5 req(s) | Total in Redis: 10/10
ðŸš« BLOCKED | IP: ::1 | Worker PID 1236: 2 req(s) | Total in Redis: 10/10 - LIMIT EXCEEDED
```

**Key Observations**:
- Different worker PIDs = concurrent processing
- Redis count increases = rate limiting works across all workers
- After 10 requests = 429 errors (Too Many Requests)

### Log Analyzer Output
```json
{
  "most_active_ips": [
    { "ip": "192.168.1.1", "requests": 45 }
  ],
  "top_endpoints": [
    { "endpoint": "/api/users", "requests": 127 }
  ],
  "latency_distribution_ms": {
    "min": 12,
    "max": 980,
    "avg": 245,
    "p50": 220,
    "p95": 650,
    "p99": 890
  },
  "error_patterns": {
    "4xx_by_endpoint": {
      "/api/auth (401)": 23,
      "/api/users (403)": 12
    },
    "5xx_by_endpoint": {
      "/api/orders (500)": 5
    }
  }
}
```

---

## Project Structure

```
Mini-Api-Rate-Limiter/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ rate-limitter/
â”‚   â”‚   â”œâ”€â”€ server.js              # Clustering & master process
â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚   â””â”€â”€ ratelimiter.js     # Rate limiting logic
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â””â”€â”€ testapi.js         # API endpoints
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ redisclient.js     # Redis connection
â”‚   â”œâ”€â”€ log-analyzer/
â”‚   â”‚   â”œâ”€â”€ analyzer.js            # Log processing
â”‚   â”‚   â””â”€â”€ output/
â”‚   â”‚       â””â”€â”€ summary.json       # Results
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.js              # Winston logger
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test-cluster.js            # Concurrency test
â”‚   â””â”€â”€ test-sequential.js         # Rate limit test
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_api_logs.json       # Sample logs
â”œâ”€â”€ IMPLEMENTATION.md              # Detailed technical guide
â””â”€â”€ README.md
```

## Common Issues

**Q: I see "1/10" for multiple requests**
- Race condition in concurrent requests (expected)
- See `IMPLEMENTATION.md` for detailed explanation
- Use `npm run test:sequential` for clean counting

**Q: All requests blocked immediately**
- Wait 60 seconds for Redis window to expire
- Or flush Redis: `redis-cli FLUSHALL`

